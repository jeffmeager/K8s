// Requires helm, kubectl, terraform, aws cli v2 in runtime
// build_timestamp used to ensure unique keys in AWS Secrets Manager as it leaves them behind for recovery. Could us force-delete but this is more reliable.

pipeline {
    agent any

    environment {
        PATH                = "/opt/homebrew/bin:/usr/local/bin:${env.PATH}"
        AWS_DEFAULT_REGION  = 'us-east-1'
        EKS_CLUSTER_NAME    = 'challenge-eks-cluster'
    }

    stages {
        stage('Checkout') {
            steps {
                git url: 'https://github.com/jeffmeager/K8s.git', branch: 'main'
            }
        }

        stage('Terraform & Deploy') {
            steps {
                script {
                    def BUILD_TIMESTAMP = new Date().format('yyyyMMddHHmmss')
                    env.BUILD_TIMESTAMP = BUILD_TIMESTAMP  // export to env for all sh steps
                }

                withCredentials([
                    string(credentialsId: 'aws-access-key-id', variable: 'AWS_ACCESS_KEY_ID'),
                    string(credentialsId: 'aws-secret-access-key', variable: 'AWS_SECRET_ACCESS_KEY'),
                    string(credentialsId: 'mongodb-username', variable: 'TF_VAR_mongodb_username'),
                    string(credentialsId: 'mongodb-password', variable: 'TF_VAR_mongodb_password'),
                    string(credentialsId: 'github_token', variable: 'TF_VAR_github_token'),
                    string(credentialsId: 'github_token', variable: 'github_token')
                ]) {
                    dir('terraform') {
                        sh """
                            set -o errexit -o pipefail -o nounset
                            terraform init \
                            -backend-config="bucket=jeffmeager-challenge-terraform-state-bucket" \
                            -backend-config="key=challenge/terraform.tfstate" \
                            -backend-config="region=ap-southeast-2"

                            terraform apply -auto-approve \
                                -var="region=${AWS_DEFAULT_REGION}" \
                                -var="build_timestamp=${BUILD_TIMESTAMP}"
                        """
                    }

                    // refresh kubeconfig to use the new EKS cluster
                    sh '''
                        set -o errexit -o pipefail -o nounset
                        echo "üîß Updating kubeconfig..."
                        aws eks --region ${AWS_DEFAULT_REGION} \
                          update-kubeconfig \
                          --name ${EKS_CLUSTER_NAME}
                    '''

                    // Wait for nodes ready (prevents race conditions)
                    sh '''
                        set -o errexit -o pipefail -o nounset
                        echo "‚è≥ Waiting for EKS nodes to be Ready..."
                        kubectl wait --for=condition=Ready node --all --timeout=120s
                    '''

                    // Add PAT secret to call private repo
                    sh '''
                        set -o errexit -o pipefail -o nounset
                        kubectl create secret docker-registry ghcr-pull-secret \
                            --docker-server=ghcr.io \
                            --docker-username="jeffmeager" \
                            --docker-password=$github_token \
                            --docker-email=your-email@example.com \
                            --dry-run=client -o yaml | kubectl apply -f -
                    '''

                    // Install CSI Driver and AWS Provider
                    sh '''
                        echo "üì¶ Adding Helm repos..."
                        set -o errexit -o pipefail -o nounset
                        helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts || true
                        helm repo add aws-secrets-provider https://aws.github.io/secrets-store-csi-driver-provider-aws || true
                        helm repo update

                        echo "üîç Checking if CSI Driver is already installed..."
                        if ! helm status csi-secrets-store -n kube-system > /dev/null 2>&1; then
                            echo "üöÄ Installing CSI Driver..."
                            helm install csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver \
                            --namespace kube-system \
                            --version 1.3.4 \
                            --create-namespace \
                            --wait \
                            --set syncSecret.enabled=true \
                            --set enableSecretRotation=true \
                            --set enableCSIStorageCapacity=true
                        else
                            echo "‚úÖ CSI Driver already installed. Skipping."
                        fi

                        echo "üîç Checking if AWS Provider is already installed..."
                        if ! helm status secrets-store-csi-driver-provider-aws -n kube-system > /dev/null 2>&1; then
                            echo "üîê Installing AWS Provider..."
                            helm install secrets-store-csi-driver-provider-aws aws-secrets-provider/secrets-store-csi-driver-provider-aws \
                            --namespace kube-system \
                            --version 0.2.0 \
                            --wait
                        else
                            echo "‚úÖ AWS Provider already installed. Skipping."
                        fi
                    '''

                    // Apply SecretProviderClass with current BUILD_TIMESTAMP
                    dir('kubernetes/deployments') {
                        sh """
                            set -o errexit -o pipefail -o nounset
                            echo "Applying SecretProviderClass with current BUILD_TIMESTAMP=${BUILD_TIMESTAMP}"
                            envsubst < secretproviderclass-template.yaml | kubectl apply -f -
                        """
                    }

                    // Apply Kubernetes manifests
                    dir('kubernetes/deployments') {
                        sh '''
                            set -o errexit -o pipefail -o nounset
                            kubectl apply -f cluster-admin-rolebinding.yaml
                        '''
                    }

                    dir('kubernetes/deployments') {
                        sh '''
                            set -o errexit -o pipefail -o nounset
                            kubectl apply -f webapp-deployment.yaml
                        '''
                    }

                    dir('kubernetes/services') {
                        sh '''
                            set -o errexit -o pipefail -o nounset
                            kubectl apply -f webapp-service.yaml
                        '''
                    }
                }
            }
        }
    }

    post {
        success {
            echo 'üöÄ Infrastructure and workloads successfully deployed'
        }
        failure {
            echo '‚ö†Ô∏è Deployment encountered issues'
        }
    }
}
